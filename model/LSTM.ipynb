{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb0f740-ed37-4dcc-8c58-c7a9d98dccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/250], Loss per (random) batch: 1.0540, Running Loss (per N epoch): 2201.1427\n",
      "Epoch [20/250], Loss per (random) batch: 0.7248, Running Loss (per N epoch): 2095.6341\n",
      "Epoch [30/250], Loss per (random) batch: 0.3872, Running Loss (per N epoch): 2087.2316\n",
      "Epoch [40/250], Loss per (random) batch: 0.4423, Running Loss (per N epoch): 2078.6756\n",
      "Epoch [50/250], Loss per (random) batch: 0.3332, Running Loss (per N epoch): 2063.2610\n",
      "Epoch [60/250], Loss per (random) batch: 0.9519, Running Loss (per N epoch): 2056.8635\n",
      "Epoch [70/250], Loss per (random) batch: 1.2802, Running Loss (per N epoch): 2053.1093\n",
      "Epoch [80/250], Loss per (random) batch: 0.3764, Running Loss (per N epoch): 2041.7153\n",
      "Epoch [90/250], Loss per (random) batch: 0.4356, Running Loss (per N epoch): 2047.1703\n",
      "Epoch [100/250], Loss per (random) batch: 0.9203, Running Loss (per N epoch): 2043.4591\n",
      "Epoch [110/250], Loss per (random) batch: 0.2857, Running Loss (per N epoch): 2030.7886\n",
      "Epoch [120/250], Loss per (random) batch: 0.6293, Running Loss (per N epoch): 2044.6801\n",
      "Epoch [130/250], Loss per (random) batch: 0.5416, Running Loss (per N epoch): 2058.0425\n",
      "Epoch [140/250], Loss per (random) batch: 1.2392, Running Loss (per N epoch): 2048.1659\n",
      "Epoch [150/250], Loss per (random) batch: 0.6036, Running Loss (per N epoch): 2047.3784\n",
      "Epoch [160/250], Loss per (random) batch: 0.8120, Running Loss (per N epoch): 2038.6182\n",
      "Epoch [170/250], Loss per (random) batch: 0.9443, Running Loss (per N epoch): 2041.7219\n",
      "Epoch [180/250], Loss per (random) batch: 0.5046, Running Loss (per N epoch): 2046.2036\n",
      "Epoch [190/250], Loss per (random) batch: 0.5839, Running Loss (per N epoch): 2022.8151\n",
      "Epoch [200/250], Loss per (random) batch: 1.1435, Running Loss (per N epoch): 2015.3995\n",
      "Epoch [210/250], Loss per (random) batch: 0.6367, Running Loss (per N epoch): 2010.9114\n",
      "Epoch [220/250], Loss per (random) batch: 0.6289, Running Loss (per N epoch): 2017.9486\n",
      "Epoch [230/250], Loss per (random) batch: 0.6891, Running Loss (per N epoch): 2008.4630\n",
      "Epoch [240/250], Loss per (random) batch: 0.5643, Running Loss (per N epoch): 2009.3582\n",
      "Epoch [250/250], Loss per (random) batch: 0.5773, Running Loss (per N epoch): 2014.0087\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# classifer notebook\n",
    "#\n",
    "\n",
    "# for Colab paths\n",
    "# import sys\n",
    "# sys.path.append('/content/')\n",
    "#\n",
    "#!nvidia-smi\n",
    "#!nvidia-smi -q\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "from LSTMLandmarkDataset import LSTMLandmarkDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "#\n",
    "# MODEL\n",
    "#\n",
    "# Should be 63 classes:\n",
    "# Price B/S * 10                 -> 20\n",
    "# QTY B/S * 10                   -> 20\n",
    "# QTY B/S 10,20-100              -> 20\n",
    "# Action Cancel, Market, Garbage ->  3\n",
    "#                                -> 63\n",
    "\n",
    "\n",
    "\n",
    "# Define LSTM model\n",
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "#\n",
    "# PARAMS\n",
    "#\n",
    "\n",
    "batch_size = 12\n",
    "hidden_size = 72\n",
    "learning_rate = .01\n",
    "num_epochs = 250\n",
    "sequence_length = 1\n",
    "\n",
    "#\n",
    "# INITIAL DATA\n",
    "#\n",
    "\n",
    "# for directory load each file\n",
    "# generate mapping of file -> class -> idx\n",
    "# if available copy data to gpu (model set below)\n",
    "# typically need model + tensors (label and value) moved over. \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x.values).to(device))\n",
    "])\n",
    "target_transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x).to(device))\n",
    "])\n",
    "\n",
    "dataset = LSTMLandmarkDataset(\"/home/jovyan/train/lstm_data\",\n",
    "                              \"/home/jovyan/model\",\n",
    "                              sequence_length,\n",
    "                              transform=transformations,\n",
    "                              target_transform = target_transformations)\n",
    "\n",
    "\n",
    "num_classes = dataset.num_class\n",
    "input_size = dataset.input_size() #2 * (21 * 3) + 12 + 1 + 10 #149 + 1 label = 150\n",
    "\n",
    "# Split train and test indices\n",
    "num_samples = len(dataset)\n",
    "indices = list(range(num_samples))\n",
    "split = int(np.floor(0.2 * num_samples)) # 20% test set\n",
    "np.random.shuffle(indices)\n",
    "training_indices, validation_indices = indices[split:], indices[:split]\n",
    "\n",
    "       \n",
    "# remove subset as these now need to be grouped\n",
    "train_sampler = SubsetRandomSampler(training_indices)\n",
    "valid_sampler = SubsetRandomSampler(validation_indices)\n",
    "    \n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# INIT MODELS, LOSS FN, GRAD\n",
    "#\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "#\n",
    "# TRAIN\n",
    "#\n",
    "\n",
    "running_loss_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (labels, landmarks) in enumerate(train_dataloader):  \n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(landmarks)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # zero out accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # NB: len(dataloader) is num of batches\n",
    "        running_loss_epoch += loss.item()\n",
    "        \n",
    "        if ((epoch+1) % 10 == 0) and ((batch_idx+1) % len(train_dataloader) == 0):\n",
    "            print ('Epoch [{}/{}], Loss per (random) batch: {:.4f}, Running Loss (per N epoch): {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, loss.item(), running_loss_epoch))\n",
    "            running_loss_epoch = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb9280b-af3f-4e85-8853-b1e82390b57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%landmarks : Double(1, 1, 150, strides=[150, 150, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Double(7, 72, strides=[72, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Double(7, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::LSTM_118 : Double(1, 288, 150, strides=[43200, 150, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_119 : Double(1, 288, 72, strides=[20736, 72, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_120 : Double(1, 576, strides=[576, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Concat_121 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %onnx::Concat_122 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_0\"](%onnx::Concat_121)\n",
      "  %onnx::Expand_7 : Double(1, 1, 72, strides=[72, 72, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"Constant_1\"]() # /tmp/ipykernel_103757/688871968.py:45:0\n",
      "  %onnx::Expand_8 : Double(1, 1, 72, strides=[72, 72, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"Constant_2\"]() # /tmp/ipykernel_103757/688871968.py:45:0\n",
      "  %onnx::Shape_9 : Double(1, 1, 150, strides=[150, 150, 1], device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"Transpose_3\"](%landmarks) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::LSTM_10 : Tensor? = prim::Constant() # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Gather_70 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_4\"](%onnx::Shape_9) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Gather_71 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_5\"]() # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Unsqueeze_72 : Long(device=cpu) = onnx::Gather[onnx_name=\"Gather_6\"](%onnx::Gather_70, %onnx::Gather_71) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Unsqueeze_73 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_7\"]()\n",
      "  %onnx::Concat_74 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"Unsqueeze_8\"](%onnx::Unsqueeze_72, %onnx::Unsqueeze_73)\n",
      "  %onnx::Concat_75 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={72}, onnx_name=\"Constant_9\"]() # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Expand_79 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_10\"](%onnx::Concat_121, %onnx::Concat_74, %onnx::Concat_75) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::LSTM_80 : Double(1, 1, 72, device=cpu) = onnx::Expand[onnx_name=\"Expand_11\"](%onnx::Expand_7, %onnx::Expand_79) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Gather_81 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_12\"](%onnx::Shape_9) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Gather_82 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_13\"]() # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Unsqueeze_83 : Long(device=cpu) = onnx::Gather[onnx_name=\"Gather_14\"](%onnx::Gather_81, %onnx::Gather_82) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Unsqueeze_84 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_15\"]()\n",
      "  %onnx::Concat_85 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"Unsqueeze_16\"](%onnx::Unsqueeze_83, %onnx::Unsqueeze_84)\n",
      "  %onnx::Concat_86 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={72}, onnx_name=\"Constant_17\"]() # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Expand_90 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_18\"](%onnx::Concat_122, %onnx::Concat_85, %onnx::Concat_86) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::LSTM_91 : Double(1, 1, 72, device=cpu) = onnx::Expand[onnx_name=\"Expand_19\"](%onnx::Expand_8, %onnx::Expand_90) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Squeeze_92 : Double(1, 1, 1, 72, strides=[72, 72, 72, 1], device=cpu), %93 : Double(1, 1, 72, strides=[72, 72, 1], requires_grad=1, device=cpu), %94 : Double(1, 1, 72, strides=[72, 72, 1], requires_grad=1, device=cpu) = onnx::LSTM[hidden_size=72, onnx_name=\"LSTM_20\"](%onnx::Shape_9, %onnx::LSTM_118, %onnx::LSTM_119, %onnx::LSTM_120, %onnx::LSTM_10, %onnx::LSTM_80, %onnx::LSTM_91) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Squeeze_95 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_21\"]() # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Transpose_96 : Double(1, 1, 72, strides=[72, 72, 1], device=cpu) = onnx::Squeeze[onnx_name=\"Squeeze_22\"](%onnx::Squeeze_92, %onnx::Squeeze_95) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Gather_97 : Double(1, 1, 72, strides=[72, 72, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"Transpose_23\"](%onnx::Transpose_96) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:751:0\n",
      "  %onnx::Gather_98 : Long(device=cpu) = onnx::Constant[value={-1}, onnx_name=\"Constant_24\"]()\n",
      "  %onnx::Gemm_99 : Double(1, 72, strides=[72, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=1, onnx_name=\"Gather_25\"](%onnx::Gather_97, %onnx::Gather_98) # /tmp/ipykernel_103757/688871968.py:46:0\n",
      "  %class : Double(1, 7, strides=[7, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_26\"](%onnx::Gemm_99, %fc.weight, %fc.bias) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%class)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:3227: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EXPORT\n",
    "#\n",
    "# NB: LandmarkDataset.py updates meta.json with class index\n",
    "#\n",
    "\n",
    "dummy_input = torch.zeros(1, dataset.seq_len, input_size)\n",
    "#model.load_state_dict(torch.load('./model_overfit.pt'))\n",
    "torch.onnx.export(model, dummy_input, 'onnx_model_LSTM.onnx', export_params=True,\n",
    "                  input_names = ['landmarks'], output_names = ['class'], verbose=True)\n",
    "\n",
    "torch.save(model, \"./model_LSTM.pt\") \n",
    "#import onnx\n",
    "#onnx_model = onnx.load(\"./onnx_model.onnx\")\n",
    "#onnx.checker.check_model(onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedf07ca-dcce-49e0-b61f-d99fbb3e4f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Accuracy 678/882 : 0.7687\n",
      "------------\n",
      "0  0.2788\n",
      "5  0.4000\n",
      "4  0.4059\n",
      "1  0.4073\n",
      "6  0.4091\n",
      "2  0.4305\n",
      "3  0.4653\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EVAL / INFERENCE\n",
    "#\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "accuracy = 0\n",
    "count = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    matches = {}\n",
    "    counts = {}\n",
    "    \n",
    "    for batch_idx, (labels, landmarks) in enumerate(valid_dataloader):  \n",
    "        out = model(landmarks)\n",
    "        prob = softmax(out.data)     #setup for threshold or 'garbage' class\n",
    "        _, klass = torch.max(out.data, 1)\n",
    "\n",
    "        #print(klass, labels, klass==labels)\n",
    "        #print(prob)\n",
    "        #print(\"-----\")\n",
    "\n",
    "        # x is class\n",
    "        for i, x in enumerate(klass.tolist()):\n",
    "            label = int(labels[i])\n",
    "            if x == labels[i]:\n",
    "                matches[x] = matches.get(x, 0) + 1\n",
    "            else:\n",
    "                # track label-side class as well\n",
    "                matches[x] = matches.get(x, 0)\n",
    "                matches[ label ] = matches.get(label, 0)\n",
    "                                \n",
    "            counts[label] = counts.get(label, 0) + 1\n",
    "            counts[x] = counts.get(x, 0) + 1\n",
    "            \n",
    "        # aggregate accuracy\n",
    "        accuracy += (klass == labels).sum().item()\n",
    "        count += len(labels)\n",
    "        \n",
    "\n",
    "print('--------')\n",
    "print(\"Accuracy {}/{} : {:.4f}\".format(accuracy, count, accuracy/count))\n",
    "print(\"------------\")\n",
    "\n",
    "# class vs percentage label match - track whether some gestures have bad data\n",
    "acc = sorted([(int(k), v / counts.get(k, 1)) for k,v in matches.items()], key=lambda x:x[1])\n",
    "for klass, match in acc:\n",
    "    print(klass, \" {:.4f}\".format(match))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
