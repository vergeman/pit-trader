{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b2aa57-f856-4ac7-85f5-6e59b77f0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/250], Loss per (random) batch: 1.1617, Running Loss (per N epoch): 15310.5742\n",
      "Epoch [20/250], Loss per (random) batch: 0.4129, Running Loss (per N epoch): 11336.3192\n",
      "Epoch [30/250], Loss per (random) batch: 0.2246, Running Loss (per N epoch): 10577.6996\n",
      "Epoch [40/250], Loss per (random) batch: 0.9043, Running Loss (per N epoch): 10061.8993\n",
      "Epoch [50/250], Loss per (random) batch: 1.2999, Running Loss (per N epoch): 9685.4794\n",
      "Epoch [60/250], Loss per (random) batch: 2.0129, Running Loss (per N epoch): 9515.7403\n",
      "Epoch [70/250], Loss per (random) batch: 3.1914, Running Loss (per N epoch): 9253.8470\n",
      "Epoch [80/250], Loss per (random) batch: 4.2592, Running Loss (per N epoch): 9164.3803\n",
      "Epoch [90/250], Loss per (random) batch: 0.5148, Running Loss (per N epoch): 9064.7203\n",
      "Epoch [100/250], Loss per (random) batch: 0.4376, Running Loss (per N epoch): 8948.9968\n",
      "Epoch [110/250], Loss per (random) batch: 0.0215, Running Loss (per N epoch): 8915.5206\n",
      "Epoch [120/250], Loss per (random) batch: 1.5104, Running Loss (per N epoch): 8919.0035\n",
      "Epoch [130/250], Loss per (random) batch: 0.8769, Running Loss (per N epoch): 8802.8287\n",
      "Epoch [140/250], Loss per (random) batch: 0.6234, Running Loss (per N epoch): 8765.6846\n",
      "Epoch [150/250], Loss per (random) batch: 0.3975, Running Loss (per N epoch): 8751.8711\n",
      "Epoch [160/250], Loss per (random) batch: 0.9658, Running Loss (per N epoch): 8667.9508\n",
      "Epoch [170/250], Loss per (random) batch: 0.4850, Running Loss (per N epoch): 8714.1620\n",
      "Epoch [180/250], Loss per (random) batch: 0.5724, Running Loss (per N epoch): 8618.5846\n",
      "Epoch [190/250], Loss per (random) batch: 0.4156, Running Loss (per N epoch): 8564.3557\n",
      "Epoch [200/250], Loss per (random) batch: 0.7098, Running Loss (per N epoch): 8643.4242\n",
      "Epoch [210/250], Loss per (random) batch: 1.2072, Running Loss (per N epoch): 8540.7878\n",
      "Epoch [220/250], Loss per (random) batch: 0.2634, Running Loss (per N epoch): 8631.9950\n",
      "Epoch [230/250], Loss per (random) batch: 1.2934, Running Loss (per N epoch): 8512.4741\n",
      "Epoch [240/250], Loss per (random) batch: 0.7249, Running Loss (per N epoch): 8515.1773\n",
      "Epoch [250/250], Loss per (random) batch: 0.7261, Running Loss (per N epoch): 8578.0939\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# classifer notebook\n",
    "#\n",
    "\n",
    "# for Colab paths\n",
    "# import sys\n",
    "# sys.path.append('/content/')\n",
    "#\n",
    "#!nvidia-smi\n",
    "#!nvidia-smi -q\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "from LandmarkDataset import LandmarkDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "#\n",
    "# MODEL\n",
    "#\n",
    "# Should be 63 classes:\n",
    "# Price B/S * 10                 -> 20\n",
    "# QTY B/S * 10                   -> 20\n",
    "# QTY B/S 10,20-100              -> 20\n",
    "# Action Cancel, Market, Garbage ->  3\n",
    "#                                -> 63\n",
    "class NN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "        #self.fc2 = torch.nn.Linear(hidden_size, 48)\n",
    "        #self.fc3 = torch.nn.Linear(48, num_classes)\n",
    "        \n",
    "        #44 with dropout .025\n",
    "        #28 with .01\n",
    "        self.dropout = torch.nn.Dropout(p=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        #out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        #out = self.relu(out)\n",
    "        #out = self.dropout(out)\n",
    "        \n",
    "        #out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "#\n",
    "# PARAMS\n",
    "#\n",
    "\n",
    "batch_size = 12\n",
    "hidden_size = 96\n",
    "learning_rate = .01\n",
    "num_epochs = 250\n",
    "\n",
    "\n",
    "#\n",
    "# INITIAL DATA\n",
    "#\n",
    "\n",
    "# for directory load each file\n",
    "# generate mapping of file -> class -> idx\n",
    "# if available copy data to gpu (model set below)\n",
    "# typically need model + tensors (label and value) moved over. \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x.values).to(device))\n",
    "])\n",
    "target_transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x).to(device))\n",
    "])\n",
    "\n",
    "dataset = LandmarkDataset(\"/home/jovyan/train/data\",\n",
    "                          \"/home/jovyan/model\",\n",
    "                          transform=transformations)\n",
    "\n",
    "num_classes = dataset.num_class\n",
    "input_size = dataset.input_size() #2 * (21 * 3) + 12 + 1 + 10 #149\n",
    "\n",
    "training_indices, validation_indices = dataset.train_validation_indices(split_p = .2)\n",
    "        \n",
    "train_sampler = SubsetRandomSampler(training_indices)\n",
    "valid_sampler = SubsetRandomSampler(validation_indices)\n",
    "    \n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "\n",
    "#\n",
    "# INIT MODELS, LOSS FN, GRAD\n",
    "#\n",
    "\n",
    "model = NN(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "#\n",
    "# TRAIN\n",
    "#\n",
    "\n",
    "running_loss_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (labels, landmarks) in enumerate(train_dataloader):  \n",
    "\n",
    "        # zero out accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(landmarks)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # NB: len(dataloader) is num of batches\n",
    "        running_loss_epoch += loss.item()\n",
    "        \n",
    "        if ((epoch+1) % 10 == 0) and ((batch_idx+1) % len(train_dataloader) == 0):\n",
    "            print ('Epoch [{}/{}], Loss per (random) batch: {:.4f}, Running Loss (per N epoch): {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, loss.item(), running_loss_epoch))\n",
    "            running_loss_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5924c04f-0970-4ffa-a506-c48ee798ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%landmarks : Double(150, strides=[1], requires_grad=0, device=cpu),\n",
      "      %fc1.bias : Double(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc2.bias : Double(63, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::MatMul_12 : Double(150, 96, strides=[1, 150], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_13 : Double(96, 63, strides=[1, 96], requires_grad=0, device=cpu)):\n",
      "  %onnx::Add_6 : Double(96, strides=[1], device=cpu) = onnx::MatMul[onnx_name=\"MatMul_0\"](%landmarks, %onnx::MatMul_12) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input : Double(96, strides=[1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_1\"](%fc1.bias, %onnx::Add_6) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::MatMul_8 : Double(96, strides=[1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_2\"](%input) # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %onnx::Add_10 : Double(63, strides=[1], device=cpu) = onnx::MatMul[onnx_name=\"MatMul_3\"](%onnx::MatMul_8, %onnx::MatMul_13) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %class : Double(63, strides=[1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_4\"](%fc2.bias, %onnx::Add_10) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%class)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EXPORT\n",
    "#\n",
    "# NB: LandmarkDataset.py updates meta.json with class index\n",
    "#\n",
    "dummy_input = torch.zeros(input_size)\n",
    "#model.load_state_dict(torch.load('./model_overfit.pt'))\n",
    "torch.onnx.export(model, dummy_input, 'onnx_model.onnx', export_params=True,\n",
    "                  input_names = ['landmarks'], output_names = ['class'], verbose=True)\n",
    "\n",
    "#import onnx\n",
    "#onnx_model = onnx.load(\"./onnx_model.onnx\")\n",
    "#onnx.checker.check_model(onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1614e97-470f-4927-bde4-e10e3529e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Accuracy 2055/2880 : 0.7135\n",
      "------------\n",
      "2  0.1860\n",
      "26  0.1954\n",
      "46  0.2239\n",
      "4  0.2250\n",
      "24  0.2330\n",
      "6  0.2340\n",
      "8  0.2344\n",
      "14  0.2353\n",
      "27  0.2887\n",
      "19  0.2903\n",
      "47  0.2923\n",
      "23  0.3023\n",
      "51  0.3069\n",
      "45  0.3088\n",
      "29  0.3188\n",
      "36  0.3191\n",
      "0  0.3261\n",
      "18  0.3273\n",
      "13  0.3333\n",
      "3  0.3333\n",
      "5  0.3333\n",
      "28  0.3385\n",
      "40  0.3387\n",
      "22  0.3396\n",
      "38  0.3453\n",
      "10  0.3455\n",
      "15  0.3462\n",
      "25  0.3488\n",
      "54  0.3492\n",
      "53  0.3509\n",
      "34  0.3553\n",
      "41  0.3575\n",
      "44  0.3600\n",
      "7  0.3636\n",
      "49  0.3636\n",
      "61  0.3636\n",
      "55  0.3656\n",
      "33  0.3678\n",
      "1  0.3704\n",
      "56  0.3704\n",
      "21  0.3784\n",
      "42  0.3816\n",
      "39  0.3846\n",
      "43  0.3853\n",
      "57  0.3874\n",
      "9  0.3882\n",
      "62  0.3929\n",
      "12  0.3956\n",
      "52  0.3976\n",
      "30  0.3983\n",
      "32  0.4068\n",
      "60  0.4204\n",
      "16  0.4225\n",
      "20  0.4231\n",
      "35  0.4242\n",
      "17  0.4321\n",
      "37  0.4384\n",
      "48  0.4444\n",
      "58  0.4571\n",
      "11  0.4659\n",
      "31  0.4742\n",
      "50  0.4900\n",
      "59  0.5000\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EVAL\n",
    "#\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "accuracy = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    \n",
    "    matches = {}\n",
    "    counts = {}\n",
    "    \n",
    "    for batch_idx, (labels, landmarks) in enumerate(valid_dataloader):  \n",
    "        out = model(landmarks)\n",
    "        prob = softmax(out.data)     #setup for threshold or 'garbage' class\n",
    "        _, klass = torch.max(out.data, 1)\n",
    "\n",
    "        #print(klass, labels, klass==labels)\n",
    "        #print(prob)\n",
    "        #print(\"-----\")\n",
    "\n",
    "        # x is class\n",
    "        for i, x in enumerate(klass.tolist()):\n",
    "            label = int(labels[i])\n",
    "            if x == labels[i]:\n",
    "                matches[x] = matches.get(x, 0) + 1\n",
    "            else:\n",
    "                # track label-side class as well\n",
    "                matches[x] = matches.get(x, 0)\n",
    "                matches[ label ] = matches.get(label, 0)\n",
    "                                \n",
    "            counts[label] = counts.get(label, 0) + 1\n",
    "            counts[x] = counts.get(x, 0) + 1\n",
    "            \n",
    "        # aggregate accuracy\n",
    "        accuracy += (klass == labels).sum().item()\n",
    "        count += len(labels)\n",
    "        \n",
    "\n",
    "print('--------')\n",
    "print(\"Accuracy {}/{} : {:.4f}\".format(accuracy, count, accuracy/count))\n",
    "print(\"------------\")\n",
    "\n",
    "# class vs percentage label match - track whether some gestures have bad data\n",
    "acc = sorted([(int(k), v / counts.get(k, 1)) for k,v in matches.items()], key=lambda x:x[1])\n",
    "for klass, match in acc:\n",
    "    print(klass, \" {:.4f}\".format(match))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d38715a-326e-49cd-8f92-b3bfc8697b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
