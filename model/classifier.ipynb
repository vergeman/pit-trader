{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b2aa57-f856-4ac7-85f5-6e59b77f0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/250], Loss: 1.2211, Running Loss (per N epoch): 148.8787\n",
      "Epoch [20/250], Loss: 0.3399, Running Loss (per N epoch): 81.5112\n",
      "Epoch [30/250], Loss: 0.4593, Running Loss (per N epoch): 41.8602\n",
      "Epoch [40/250], Loss: 0.0162, Running Loss (per N epoch): 32.1291\n",
      "Epoch [50/250], Loss: 0.0179, Running Loss (per N epoch): 23.0621\n",
      "Epoch [60/250], Loss: 0.2397, Running Loss (per N epoch): 21.6884\n",
      "Epoch [70/250], Loss: 0.0198, Running Loss (per N epoch): 17.9256\n",
      "Epoch [80/250], Loss: 0.1140, Running Loss (per N epoch): 18.0688\n",
      "Epoch [90/250], Loss: 0.0170, Running Loss (per N epoch): 8.9599\n",
      "Epoch [100/250], Loss: 0.0000, Running Loss (per N epoch): 12.2236\n",
      "Epoch [110/250], Loss: 0.0702, Running Loss (per N epoch): 9.1524\n",
      "Epoch [120/250], Loss: 0.0000, Running Loss (per N epoch): 8.9565\n",
      "Epoch [130/250], Loss: 0.0151, Running Loss (per N epoch): 7.7721\n",
      "Epoch [140/250], Loss: 0.0210, Running Loss (per N epoch): 6.3685\n",
      "Epoch [150/250], Loss: 3.4608, Running Loss (per N epoch): 13.7385\n",
      "Epoch [160/250], Loss: 0.0066, Running Loss (per N epoch): 17.9734\n",
      "Epoch [170/250], Loss: 0.1098, Running Loss (per N epoch): 9.5172\n",
      "Epoch [180/250], Loss: 0.0009, Running Loss (per N epoch): 11.4966\n",
      "Epoch [190/250], Loss: 0.0161, Running Loss (per N epoch): 10.0978\n",
      "Epoch [200/250], Loss: 0.0011, Running Loss (per N epoch): 17.0325\n",
      "Epoch [210/250], Loss: 0.0002, Running Loss (per N epoch): 9.3093\n",
      "Epoch [220/250], Loss: 0.0658, Running Loss (per N epoch): 12.9430\n",
      "Epoch [230/250], Loss: 0.0148, Running Loss (per N epoch): 14.3373\n",
      "Epoch [240/250], Loss: 0.0001, Running Loss (per N epoch): 6.8120\n",
      "Epoch [250/250], Loss: 0.0168, Running Loss (per N epoch): 10.9072\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# classifer notebook\n",
    "#\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "from LandmarkDataset import LandmarkDataset\n",
    "\n",
    "#\n",
    "# MODEL\n",
    "#\n",
    "\n",
    "class NN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "        #self.fc2 = torch.nn.Linear(hidden_size, 48)\n",
    "        #self.fc3 = torch.nn.Linear(48, num_classes)\n",
    "        self.dropout = torch.nn.Dropout(p=0.05)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        #out = self.relu(out)\n",
    "        #out = self.dropout(out)\n",
    "        \n",
    "        #out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "#\n",
    "# PARAMS\n",
    "#\n",
    "\n",
    "batch_size = 4\n",
    "hidden_size = 96\n",
    "learning_rate = .01\n",
    "num_epochs = 250\n",
    "\n",
    "\n",
    "#\n",
    "# INITIAL DATA\n",
    "#\n",
    "\n",
    "# for directory load each file\n",
    "# generate mapping of file -> class -> idx\n",
    "\n",
    "transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x.values).float())\n",
    "])\n",
    "\n",
    "dataset = LandmarkDataset(\"/home/jovyan/train/data/\",\n",
    "                          transform=transformations)\n",
    "\n",
    "num_classes = dataset.num_class\n",
    "input_size = dataset.input_size #2 * (21 * 3) + 12 #138\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# INIT MODELS, LOSS FN, GRAD\n",
    "#\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NN(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "#\n",
    "# TRAIN\n",
    "#\n",
    "\n",
    "running_loss_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (labels, landmarks) in enumerate(dataloader):  \n",
    "\n",
    "        # zero out accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(landmarks)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # NB: len(dataloader) is num of batches\n",
    "        running_loss_epoch += loss.item()\n",
    "        if ((epoch+1) % 10 == 0) and ((batch_idx+1) % len(dataloader) == 0):\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}, Running Loss (per N epoch): {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, loss.item(), running_loss_epoch))\n",
    "            running_loss_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5924c04f-0970-4ffa-a506-c48ee798ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%landmarks : Float(138, strides=[1], requires_grad=0, device=cpu),\n",
      "      %fc1.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc2.bias : Float(6, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::MatMul_12 : Float(138, 96, strides=[1, 138], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_13 : Float(96, 6, strides=[1, 96], requires_grad=0, device=cpu)):\n",
      "  %onnx::Add_6 : Float(96, strides=[1], device=cpu) = onnx::MatMul[onnx_name=\"MatMul_0\"](%landmarks, %onnx::MatMul_12) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input : Float(96, strides=[1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_1\"](%fc1.bias, %onnx::Add_6) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.3 : Float(96, strides=[1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_2\"](%input) # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %onnx::Add_10 : Float(6, strides=[1], device=cpu) = onnx::MatMul[onnx_name=\"MatMul_3\"](%input.3, %onnx::MatMul_13) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %class : Float(6, strides=[1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_4\"](%fc2.bias, %onnx::Add_10) # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%class)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EXPORT\n",
    "#\n",
    "\n",
    "dummy_input = torch.zeros(input_size)\n",
    "#model.load_state_dict(torch.load('./model_overfit.pt'))\n",
    "torch.onnx.export(model, dummy_input, 'onnx_model.onnx', export_params=True,\n",
    "                  input_names = ['landmarks'], output_names = ['class'], verbose=True)\n",
    "\n",
    "# Export idx-class map per run\n",
    "dataset_labels = pd.DataFrame( dataset.class_map.items(), columns=[\"idx\", \"label\"] )\n",
    "dataset_labels.to_csv(\"label_map.csv\", index=False)\n",
    "\n",
    "#import onnx\n",
    "#onnx_model = onnx.load(\"./onnx_model.onnx\")\n",
    "#onnx.checker.check_model(onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1614e97-470f-4927-bde4-e10e3529e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 4, 5]) tensor([2, 2, 4, 5]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0009,     0.9991,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0001,     0.9999,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0001,     0.9998,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000]])\n",
      "-----\n",
      "tensor([0, 1, 0, 1]) tensor([0, 1, 0, 1]) tensor([True, True, True, True])\n",
      "tensor([[    0.9999,     0.0001,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.9978,     0.0022,     0.0000,     0.0000,     0.0000],\n",
      "        [    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([5, 0, 5, 0]) tensor([5, 0, 5, 0]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000],\n",
      "        [    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000],\n",
      "        [    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([2, 2, 4, 1]) tensor([2, 2, 4, 1]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0001,     0.0000,     0.0000,     0.0002,     0.9998,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([2, 5, 3, 4]) tensor([2, 5, 3, 4]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000],\n",
      "        [    0.0010,     0.0000,     0.0000,     0.9962,     0.0028,     0.0000],\n",
      "        [    0.0001,     0.0000,     0.0000,     0.0005,     0.9994,     0.0000]])\n",
      "-----\n",
      "tensor([5, 0, 5, 4]) tensor([5, 0, 5, 4]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000],\n",
      "        [    0.9989,     0.0003,     0.0008,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000],\n",
      "        [    0.0003,     0.0010,     0.0007,     0.0001,     0.9978,     0.0000]])\n",
      "-----\n",
      "tensor([3, 5, 3, 1]) tensor([3, 5, 3, 1]) tensor([True, True, True, True])\n",
      "tensor([[    0.0010,     0.0000,     0.0000,     0.9962,     0.0028,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000],\n",
      "        [    0.0010,     0.0000,     0.0000,     0.9960,     0.0030,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([2, 4, 3, 1]) tensor([2, 4, 3, 1]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0001,     0.9999,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0042,     0.0000,     0.0000,     0.9957,     0.0000],\n",
      "        [    0.0008,     0.0000,     0.0000,     0.9970,     0.0023,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([2, 1, 2, 3]) tensor([2, 1, 2, 3]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0007,     0.0000,     0.0000,     0.9971,     0.0022,     0.0000]])\n",
      "-----\n",
      "tensor([2, 1, 4, 0]) tensor([2, 1, 4, 0]) tensor([True, True, True, True])\n",
      "tensor([[    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,     0.0001,     0.9999,     0.0000],\n",
      "        [    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([3, 0, 4, 2]) tensor([3, 0, 4, 2]) tensor([True, True, True, True])\n",
      "tensor([[    0.0009,     0.0000,     0.0000,     0.9965,     0.0026,     0.0000],\n",
      "        [    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0004,     0.0000,     0.0000,     0.0038,     0.9957,     0.0000],\n",
      "        [    0.0000,     0.0026,     0.9974,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([4, 2, 1, 1]) tensor([4, 2, 1, 1]) tensor([True, True, True, True])\n",
      "tensor([[    0.0002,     0.0000,     0.0000,     0.0013,     0.9985,     0.0000],\n",
      "        [    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000]])\n",
      "-----\n",
      "tensor([5]) tensor([5]) tensor([True])\n",
      "tensor([[    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000]])\n",
      "-----\n",
      "--------\n",
      "Accuracy 49/49 : 1.0000\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EVAL\n",
    "#\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "accuracy = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, (labels, landmarks) in enumerate(dataloader):  \n",
    "        out = model(landmarks)\n",
    "        prob = softmax(out.data)     #setup for threshold or 'garbage' class\n",
    "        _, klass = torch.max(out.data, 1)\n",
    "        \n",
    "        print(klass, labels, klass==labels)\n",
    "        print(prob)\n",
    "        print(\"-----\")\n",
    "        \n",
    "        accuracy += (klass == labels).sum().item()\n",
    "        count += len(labels)\n",
    "        \n",
    "\n",
    "print('--------')\n",
    "print(\"Accuracy {}/{} : {:.4f}\".format(accuracy, count, accuracy/count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d38715a-326e-49cd-8f92-b3bfc8697b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
