{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e55ff8e-69d7-48a9-bbad-a9d360ad2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len:  11620\n",
      "Validation len:  2906\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# sci kit classifiers notebook\n",
    "#\n",
    "\n",
    "# for Colab paths\n",
    "# import sys\n",
    "# sys.path.append('/content/')\n",
    "#\n",
    "#!nvidia-smi\n",
    "#!nvidia-smi -q\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "from LandmarkDataset import LandmarkDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import onnx\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x.values).to(device))\n",
    "])\n",
    "target_transformations = Compose([\n",
    "    Lambda(lambda x: torch.tensor(x).to(device))\n",
    "])\n",
    "\n",
    "dataset = LandmarkDataset(\"/home/jovyan/train/data\",\n",
    "                          \"/home/jovyan/model\",\n",
    "                          transform=transformations)\n",
    "\n",
    "num_classes = dataset.num_class\n",
    "input_size = dataset.input_size() #2 * (21 * 3) + 12 + 1 + 10 #149\n",
    " \n",
    "data = np.empty( (len(dataset), input_size), dtype=np.float64)\n",
    "labels = np.empty( len(dataset), dtype = int)\n",
    "                  \n",
    "for i, d in enumerate(dataset):\n",
    "    data[i] = np.array(d[1], dtype=np.float64)\n",
    "    labels[i] = np.round(d[0]).astype(int) \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train len: \", len(X_train))\n",
    "print(\"Validation len: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9f7bfa-dd7e-4d47-a08f-8a824ef933e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model init\n",
      "Last supported opset: 18\n",
      "--------------------\n",
      "LogisticRegression accuracy: 0.957\n",
      "Dims 1 150\n",
      "Sanity Pred [28] 28 0.5761072199764745\n",
      "Exporting onnx_model_LogisticRegression.onnx\n",
      "--------------------\n",
      "SVC accuracy: 0.907\n",
      "Dims 1 150\n",
      "Sanity Pred [28] 28 0.5305207361195617\n",
      "Exporting onnx_model_SVC.onnx\n"
     ]
    }
   ],
   "source": [
    "# Initialize the models\n",
    "print(\"model init\")\n",
    "\n",
    "#\n",
    "# Both Decision + RandomForest classifiers have export issues with running on onnx runtime web js\n",
    "#\n",
    "#   * DecisionTreeClassifer: no raw probabilities; difficult to apply an in-game threshold / cutoff value\n",
    "#   * RandomForestClassifier: typically most accurate but not by that much to overcome the gargantuan model file size \n",
    "#   * LogisticRegression: just as accurate as any of the others, smallest file size\n",
    "#   * SVC: decent, but large file size (11mb) vs LogisticRegression\n",
    "#   * GaussianNB: extremely inaccurate, ignored for now.\n",
    "#\n",
    "# \"Simple\" LogisticRegession seems best for this class of probem.\n",
    "#\n",
    "# Most models (except GaussianNB) had 90%+ accuracy, so evaluating much better than two layer NN.\n",
    "# But these also lack dropout, so not completely comparable.\n",
    "#\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(max_iter=10000),\n",
    "    #DecisionTreeClassifier(),\n",
    "    #RandomForestClassifier(),\n",
    "    SVC(probability=True),\n",
    "    #GaussianNB()\n",
    "]\n",
    "\n",
    "from skl2onnx import __max_supported_opset__\n",
    "print(\"Last supported opset:\", __max_supported_opset__)\n",
    "\n",
    "\n",
    "# Train and test each model, and compute the accuracy score\n",
    "for model in models:\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model and compute the accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"TEST\", X_test, \"PRED\", y_pred)\n",
    "    #print(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print the model's name and accuracy score\n",
    "    print(model.__class__.__name__, \"accuracy: {:.3f}\".format(accuracy) )\n",
    "    \n",
    "    \n",
    "    # Sanity check\n",
    "    X=[\n",
    "    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "    -1, -1, -1, -1, -1, -1, 0.08243870735168457, 0.3272324204444885,\n",
    "    3.296062232038821e-7, 0.11587709188461304, 0.2649609446525574,\n",
    "    -0.010733608156442642, 0.12738025188446045, 0.20119965076446533,\n",
    "    -0.02170146442949772, 0.13692301511764526, 0.1434585452079773,\n",
    "    -0.030385395511984825, 0.1565452218055725, 0.10842287540435791,\n",
    "    -0.03992266580462456, 0.07536429166793823, 0.15806376934051514,\n",
    "    -0.03490304946899414, 0.06413596868515015, 0.07703894376754761,\n",
    "    -0.04701704904437065, 0.0496293306350708, 0.031381964683532715,\n",
    "    -0.05240476876497269, 0.03681206703186035, -0.001009911298751831,\n",
    "    -0.05688896030187607, 0.03942376375198364, 0.1726135015487671,\n",
    "    -0.0374128557741642, 0.008090049028396606, 0.09009474515914917,\n",
    "    -0.04902489855885506, -0.013370007276535034, 0.04655855894088745,\n",
    "    -0.053542546927928925, -0.02887246012687683, 0.016812801361083984,\n",
    "    -0.05725706368684769, 0.012033134698867798, 0.19919347763061523,\n",
    "    -0.03908606246113777, -0.022472083568572998, 0.12650775909423828,\n",
    "    -0.049961891025304794, -0.039518654346466064, 0.08441585302352905,\n",
    "    -0.05658777803182602, -0.05035647749900818, 0.051334500312805176,\n",
    "    -0.062176283448934555, -0.006764203310012817, 0.2322888970375061,\n",
    "    -0.04069233685731888, -0.04757261276245117, 0.20167887210845947,\n",
    "    -0.05381026118993759, -0.07199111580848694, 0.1782442331314087,\n",
    "    -0.061005041003227234, -0.09040814638137817, 0.1531672477722168,\n",
    "    -0.06528844684362411, -0.04684633016586304, -0.07679343223571777,\n",
    "    0.028765380382537842, -0.07849520444869995, 0, 0, -0.0023369789123535156,\n",
    "    0.05037200450897217, -0.10711735486984253, -0.07638520002365112,\n",
    "    0.06266820430755615, -0.08347678184509277, -1, 0, -1, -1, -1, -1, -1, 1, 1,\n",
    "    1, 1, 1,\n",
    "  ];\n",
    "    X=np.array([X], dtype=np.float64)\n",
    "    print(\"Dims\", len(X), len(X[0]))\n",
    "    pred = model.predict(X)\n",
    "    pred_prob = model.predict_proba(X)\n",
    "    # Garbage - 1, 28: 5 (correct), 37: 50\n",
    "    print(\"Sanity Pred\", pred, list(pred_prob[0]).index( max(pred_prob[0])), max(pred_prob[0]) )\n",
    "\n",
    "    # Export Onnx\n",
    "    onx = to_onnx(model, X=X_train, options={LogisticRegression: {'zipmap': False}, SVC: {'zipmap': False}})\n",
    "    \n",
    "    filename = f\"onnx_model_{model.__class__.__name__}.onnx\"\n",
    "    print(f\"Exporting {filename}\")\n",
    "    \n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(onx.SerializeToString())\n",
    "        \n",
    "    model = onnx.load(filename)\n",
    "    onnx.checker.check_model(filename)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7581d375-4cf2-4f6a-b2a8-66c6b5b7f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
